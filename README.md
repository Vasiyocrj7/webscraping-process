1.)What is Web Scraping ?

Web Scraping (also termed Screen Scraping, Web Data Extraction, Web Harvesting etc.) is a technique employed to extract large amounts of data from websites whereby the data is extracted and saved to a local file in your computer or to a database in table (spreadsheet) format.https://en.wikipedia.org/wiki/Web_data_integration

Data displayed by most websites can only be viewed using a web browser. They do not offer the functionality to save a copy of this data for personal use. The only option then is to manually copy and paste the data - a very tedious job which can take many hours or sometimes days to complete. Web Scraping is the technique of automating this process, so that instead of manually copying the data from websites, the Web Scraping software will perform the same task within a fraction of the time.
https://librarycarpentry.org/lc-webscraping/01-introduction/index.html


 2.)How to easily scrape data from websites using WebHarvy ?

A web scraping software will automatically load and extract data from multiple pages of websites based on your requirement. It is either custom built for a specific website or is one which can be configured to work with any website. With the click of a button you can easily save the data available in the website to a file in your computer.

>>Practical Usage Scenarios:
1. Extract product details including price, images etc. from eCommerce websites for populating other websites, competition monitoring etc.

2. Extract business contact details including name, address, email, phone, website etc. from Yellow Pages, Google Maps etc. for marketing and lead generation.

3. Extract property details as well as agent contact details from real estate websites.

More..
Methods of Web Scraping  (https://librarycarpentry.org/lc-webscraping/04-scrapy/index.html)
1. Using software

Web Scraping software falls under 2 categories. First, which can be locally installed in your computer and second, which runs in cloud - browser based. WebHarvy, OutWit Hub, Visual Web Ripper etc. are examples of web scraping software which can be installed in your computer, whereas import.io, Mozenda etc. are examples of cloud data extraction platforms.

2. Writing code

You can hire a developer to build custom data extraction software for your specific requirement. The developer can in-turn make use of web scraping APIs which helps him/her develop the software easily. For example apify.com lets you easily get APIs to scrape data from any website.
conclusion(https://librarycarpentry.org/lc-webscraping/05-conclusion/index.html)
Methods to prevent web scraping
1. The administrator of a website can use various measures to stop or slow a bot. Some techniques include:

2. Blocking an IP address either manually or based on criteria such as geolocation and DNSRBL. This will also block all browsing from that address.

3. Disabling any web service API that the website's system might expose.

4. Bots sometimes declare who they are (using user agent strings) and can be blocked on that basis using robots.txt; 'googlebot' is an example. Other bots make no distinction between themselves and a human using a browser.

5. Bots can be blocked by monitoring excess traffic

6. Bots can sometimes be blocked with tools to verify that it is a real person accessing the site, like a CAPTCHA. Bots are sometimes coded to explicitly break specific CAPTCHA patterns or may employ third-party services that utilize human labor to read and respond in real-time to CAPTCHA challenges.

7. Commercial anti-bot services: Companies offer anti-bot and anti-scraping services for websites. A few web application firewalls have limited bot detection capabilities as well. However, many such solutions are not very effective.[27]

8. Locating bots with a honeypot or other method to identify the IP addresses of automated crawlers.

9. Obfuscation using CSS sprites to display such data as phone numbers or email addresses, at the cost of accessibility to screen reader users.

10. Because bots rely on consistency in the front-end code of a target website, adding small variations to the HTML/CSS surrounding important data and navigation elements would require more human involvement in the initial set up of a bot and if done effectively may render the target website too difficult to scrape due to the diminished ability to automate the scraping process.

Websites can declare if crawling is allowed or not in the robots(https://en.wikipedia.org/wiki/Semantic_web).txt file and allow partial access, limit the crawl rate, specify the optimal time to crawl and more

3.)WHAT IT CAN BE USED FOR?

Web scraping is used in a variety of digital businesses that rely on data harvesting. Legitimate use cases include: Search engine bots crawling a site, analyzing its content and then ranking it. ... Market research companies using scrapers to pull data from forums and social media (e.g., for sentiment analysis).

